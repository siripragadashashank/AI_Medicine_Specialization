{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe955cbf",
   "metadata": {},
   "source": [
    "## U-Net model\n",
    "In this week's assignment, you'll be using a network architecture called \"U-Net\". The name of this network architecture comes from it's U-like shape when shown in a diagram like this (image from [U-net entry on wikipedia](https://en.wikipedia.org/wiki/U-Net)): \n",
    "\n",
    "<img src=\"U-net_example_wikipedia.png\" alt=\"U-net Image\" width=\"600\"/>\n",
    "\n",
    "U-nets are commonly used for image segmentation, which will be your task in the upcoming assignment. You won't actually need to implement U-Net in the assignment, but we wanted to give you an opportunity to gain some familiarity with this architecture here before you use it in the assignment. \n",
    "\n",
    "As you can see from the diagram, this architecture features a series of down-convolutions connected by max-pooling operations, followed by a series of up-convolutions connected by upsampling and concatenation operations. Each of the down-convolutions is also connected directly to the concatenation operations in the upsampling portion of the network. For more detail on the U-Net architecture, have a look at the original [U-Net paper by Ronneberger et al. 2015](https://arxiv.org/abs/1505.04597). \n",
    "\n",
    "In this lab, you'll create a basic U-Net using Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26c6118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the elements you'll need to build your U-Net\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU\n",
    "\n",
    "from keras.layers import Conv3DTranspose as Deconvolution3D \n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "# Set the image shape to have the channels in the first dimension\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7be07",
   "metadata": {},
   "source": [
    "### The \"depth\" of your U-Net\n",
    "The \"depth\" of your U-Net is equal to the number of down-convolutions you will use. In the image above, the depth is 4 because there are 4 down-convolutions running down the left side including the very bottom of the U.\n",
    "\n",
    "For this exercise, you'll use a U-Net depth of 2, meaning you'll have 2 down-convolutions in your network. \n",
    "\n",
    "### Input layer and its \"depth\"\n",
    "\n",
    "In this lab and in the assignment, you will be doing 3D image segmentation, which is to say that, in addition to \"height\" and \"width\", your input layer will also have a \"length\". We are deliberately using the word \"length\" instead of \"depth\" here to describe the third spatial dimension of the input so as not to confuse it with the depth of the network as defined above.\n",
    "\n",
    "The shape of the input layer is `(num_channels, height, width, length)`, where `num_channels` you can think of like color channels in an image, `height`, `width` and `length` are just the size of the input.\n",
    "\n",
    "For the assignment, the values will be:\n",
    "- num_channels: 4\n",
    "- height: 160\n",
    "- width: 160\n",
    "- length: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f061df",
   "metadata": {},
   "source": [
    "## Contracting (downward) path \n",
    "Here you'll start by constructing the downward path in your network (the left side of the U-Net).  The `(height, width, length)` of the input gets smaller as you move down this path, and the number of channels increases.\n",
    "\n",
    "### Depth 0\n",
    "\n",
    "By \"depth 0\" here, we're referring to the depth of the first down-convolution in the U-net.\n",
    "\n",
    "The number of filters is specified for each depth and for each layer within that depth.\n",
    "\n",
    "The formula to use for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=0$:\n",
    "$$filters_{0} = 32 \\times (2^{0}) = 32$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f531ba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_6:0\", shape=(None, 4, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"activation_21/Relu:0\", shape=(None, 32, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"activation_22/Relu:0\", shape=(None, 64, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"max_pooling3d_3/transpose_1:0\", shape=(None, 64, 80, 80, 8), dtype=float32)\n",
      "Tensor(\"activation_23/Relu:0\", shape=(None, 64, 80, 80, 8), dtype=float32)\n",
      "Tensor(\"activation_24/Relu:0\", shape=(None, 128, 80, 80, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(4, 160, 160, 16))\n",
    "\n",
    "down_depth_0_layer_0 = Conv3D(filters=32, \n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                              )(input_layer)\n",
    "down_depth_0_layer_0 = Activation('relu')(down_depth_0_layer_0)\n",
    "\n",
    "down_depth_0_layer_1 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_0)\n",
    "down_depth_0_layer_1 = Activation('relu')(down_depth_0_layer_1)\n",
    "\n",
    "down_depth_0_layer_pool = MaxPooling3D(pool_size=(2,2,2))(down_depth_0_layer_1)\n",
    "\n",
    "down_depth_1_layer_0 = Conv3D(filters=64, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_0_layer_pool)\n",
    "\n",
    "down_depth_1_layer_0 = Activation('relu')(down_depth_1_layer_0)\n",
    "\n",
    "down_depth_1_layer_1 = Conv3D(filters=128, \n",
    "                kernel_size=(3,3,3),\n",
    "                padding='same',\n",
    "                strides=(1,1,1)\n",
    "               )(down_depth_1_layer_0)\n",
    "\n",
    "down_depth_1_layer_1 = Activation('relu')(down_depth_1_layer_1)\n",
    "\n",
    "\n",
    "\n",
    "print(input_layer)\n",
    "print(down_depth_0_layer_0)\n",
    "print(down_depth_0_layer_1)\n",
    "print(down_depth_0_layer_pool)\n",
    "print(down_depth_1_layer_0)\n",
    "print(down_depth_1_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1566e4",
   "metadata": {},
   "source": [
    "## Expanding  (upward) Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c2dbf",
   "metadata": {},
   "source": [
    "### Concatenate upsampled depth 0 with downsampled depth 0\n",
    "\n",
    "Now you'll apply a concatenation operation using the layers that are both at the same depth of 0.\n",
    "- up_depth_0_layer_0: shape is (?, 128, 160, 160, 16)\n",
    "- depth_0_layer_1: shape is (?, 64, 160, 160, 16)\n",
    "\n",
    "- Double check that both of these layers have the same height, width and length.\n",
    "- If they're the same, then they can be concatenated along axis 1 (the channel axis).\n",
    "- The (height, width, length) is (160, 160, 16) for both.\n",
    "\n",
    "Run the next cell to check that the layers you wish to concatenate have the same height, width and length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dada5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"up_sampling3d_7/concat_2:0\", shape=(None, 128, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"activation_22/Relu:0\", shape=(None, 64, 160, 160, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of layers to concatenate\n",
    "print(up_depth_0_layer_0)\n",
    "print(down_depth_0_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65112e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"up_sampling3d_8/concat_2:0\", shape=(None, 128, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"concatenate_8/concat:0\", shape=(None, 192, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"activation_25/Relu:0\", shape=(None, 64, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"activation_26/Relu:0\", shape=(None, 64, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"conv3d_6/BiasAdd:0\", shape=(None, 3, 160, 160, 16), dtype=float32)\n",
      "Tensor(\"activation_27/Sigmoid:0\", shape=(None, 3, 160, 160, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Add an upsampling operation to your network\n",
    "up_depth_0_layer_0 = UpSampling3D(size=(2,2,2))(down_depth_1_layer_1)\n",
    "\n",
    "# Add a concatenation along axis 1\n",
    "up_depth_1_concat = concatenate([up_depth_0_layer_0,\n",
    "                                 down_depth_0_layer_1],\n",
    "                                axis=1)\n",
    "\n",
    "# Add a Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_1 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_concat)\n",
    "up_depth_1_layer_1 = Activation('relu')(up_depth_1_layer_1)\n",
    "\n",
    "# Add a Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_2 = Conv3D(filters=64, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_layer_1)\n",
    "up_depth_1_layer_2 = Activation('relu')(up_depth_1_layer_2)\n",
    "\n",
    "# Add a final Conv3D with 3 filters to your network.\n",
    "final_conv = Conv3D(filters=3, #3 categories \n",
    "                    kernel_size=(1,1,1),\n",
    "                    padding='valid',\n",
    "                    strides=(1,1,1)\n",
    "                    )(up_depth_1_layer_2)\n",
    "\n",
    "# Add a sigmoid activation to your final convolution.\n",
    "final_activation = Activation('sigmoid')(final_conv)\n",
    "\n",
    "\n",
    "print(up_depth_0_layer_0)\n",
    "print(up_depth_1_concat)\n",
    "print(up_depth_1_layer_1)\n",
    "print(up_depth_1_layer_2)\n",
    "print(final_conv)\n",
    "print(final_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70c1c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile your model\n",
    "model = Model(inputs=input_layer, outputs=final_activation)\n",
    "model.compile(optimizer=Adam(lr=0.00001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "244dc289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 4, 160, 160, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 32, 160, 160, 3488        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 160, 160, 0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 64, 160, 160, 55360       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 160, 160, 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 80, 80, 8 0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 128, 80, 80,  221312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128, 80, 80,  0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_8 (UpSampling3D)  (None, 128, 160, 160 0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_8[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 64, 160, 160, 331840      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 160, 160, 0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 64, 160, 160, 110656      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 64, 160, 160, 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 3, 160, 160,  195         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 160, 160,  0           conv3d_6[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 833,507\n",
      "Trainable params: 833,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print out a summary of the model you created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c7c3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
